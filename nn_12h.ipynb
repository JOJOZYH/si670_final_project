{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('data/data.csv')\n",
    "\n",
    "# Impute missing values using interpolation\n",
    "data.interpolate(method='linear', limit_direction='forward', inplace=True)\n",
    "\n",
    "# Create a datetime column\n",
    "data['datetime'] = pd.to_datetime({\n",
    "    'year': data['year'],  # Used to create datetime, will be dropped afterward\n",
    "    'month': data['month'],\n",
    "    'day': data['day'],\n",
    "    'hour': data['hour']\n",
    "})\n",
    "\n",
    "# Set 'datetime' as the index\n",
    "data.set_index('datetime', inplace=True)\n",
    "\n",
    "# Drop the 'year' column as per your requirement\n",
    "data.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "# Extract day of the week and weekend indicator\n",
    "data['day_of_week'] = data.index.dayofweek\n",
    "data['is_weekend'] = data['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# One-hot encode 'cbwd'\n",
    "data = pd.get_dummies(data, columns=['cbwd'])\n",
    "\n",
    "# Define the number of hours ahead to predict\n",
    "n_hours_ahead = 12  # Change this value to predict different hours ahead\n",
    "\n",
    "# Shift the 'pm2.5' column to get future values\n",
    "data['pm2.5_future'] = data['pm2.5'].shift(-n_hours_ahead)\n",
    "\n",
    "# Drop rows with NaN values resulting from shifting\n",
    "data.dropna(subset=['pm2.5_future'], inplace=True)\n",
    "\n",
    "# Create the binary target variable based on 'pm2.5_future'\n",
    "threshold = 50\n",
    "data['pm2.5_binary'] = data['pm2.5_future'].apply(lambda x: 1 if x > threshold else 0)\n",
    "\n",
    "# List to hold DataFrames of lag features\n",
    "lagged_features = []\n",
    "\n",
    "# Define the features and lags\n",
    "lag_features = ['DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir']\n",
    "lags = range(1, 25)  # Lags from 1 to 24 hours\n",
    "\n",
    "# Generate lagged features for specified features\n",
    "for feature in lag_features + ['pm2.5']:\n",
    "    # Create a dictionary of lagged series\n",
    "    lagged_data = {f'{feature}_lag_{lag}': data[feature].shift(lag) for lag in lags}\n",
    "    # Create a DataFrame from the dictionary\n",
    "    lagged_df = pd.DataFrame(lagged_data)\n",
    "    # Append to the list\n",
    "    lagged_features.append(lagged_df)\n",
    "\n",
    "# Concatenate all lagged features into a single DataFrame\n",
    "lagged_features_df = pd.concat(lagged_features, axis=1)\n",
    "\n",
    "# Concatenate lagged features with the original data\n",
    "data = pd.concat([data, lagged_features_df], axis=1)\n",
    "\n",
    "# Drop rows with NaN values resulting from lagging\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Sort data by datetime\n",
    "data.sort_index(inplace=True)\n",
    "\n",
    "# Define the split point (e.g., last 20% of data for testing)\n",
    "split_fraction = 0.8\n",
    "split_point = int(len(data) * split_fraction)\n",
    "\n",
    "# Split the data\n",
    "train_data = data.iloc[:split_point]\n",
    "test_data = data.iloc[split_point:]\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_data.drop(['pm2.5', 'pm2.5_future', 'pm2.5_binary'], axis=1)\n",
    "y_train = train_data['pm2.5_binary']\n",
    "\n",
    "X_test = test_data.drop(['pm2.5', 'pm2.5_future', 'pm2.5_binary'], axis=1)\n",
    "y_test = test_data['pm2.5_binary']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify numeric features to scale\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "\n",
    "# Apply the scaler to the test data\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled[numeric_features] = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "# Check class distribution in the training set\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print(f'Class distribution in training set: {counter}')\n",
    "\n",
    "# Calculate class weights if imbalance exists\n",
    "neg, pos = np.bincount(y_train)\n",
    "total = neg + pos\n",
    "class_weight = {0: (1 / neg) * (total / 2.0),\n",
    "                1: (1 / pos) * (total / 2.0)}\n",
    "\n",
    "print(f'Calculated class weights: {class_weight}')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['Precision', 'Recall', 'AUC'])\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,  # Further split of training data for validation\n",
    "    shuffle=False,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weight  # Use class weights if imbalance exists\n",
    ")\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# AUC-ROC\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f'AUC-ROC: {auc:.4f}')\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPI8YaCsP3f4",
    "outputId": "bb25799f-fd44-44fc-ce24-a90054ac0b5e",
    "ExecuteTime": {
     "end_time": "2024-12-03T15:32:58.511283Z",
     "start_time": "2024-12-03T15:32:53.163382Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jojo1\\AppData\\Local\\Temp\\ipykernel_25808\\1019768635.py:8: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  data.interpolate(method='linear', limit_direction='forward', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set: Counter({1: 21731, 0: 13280})\n",
      "Calculated class weights: {0: np.float64(1.3181852409638555), 1: np.float64(0.8055542772997101)}\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\jojo1\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 70, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:70\u001B[0m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 70\u001B[0m   \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pywrap_tensorflow_internal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001B[39;00m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001B[39;00m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001B[39;00m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001B[39;00m\n\u001B[0;32m     75\u001B[0m \n\u001B[0;32m     76\u001B[0m \u001B[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 117\u001B[0m\n\u001B[0;32m    112\u001B[0m class_weight \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m0\u001B[39m: (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m neg) \u001B[38;5;241m*\u001B[39m (total \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2.0\u001B[39m),\n\u001B[0;32m    113\u001B[0m                 \u001B[38;5;241m1\u001B[39m: (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m pos) \u001B[38;5;241m*\u001B[39m (total \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2.0\u001B[39m)}\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCalculated class weights: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclass_weight\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 117\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dense\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\__init__.py:40\u001B[0m\n\u001B[0;32m     37\u001B[0m _os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39msetdefault(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001B[39;00m\n\u001B[1;32m---> 40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tensorflow \u001B[38;5;28;01mas\u001B[39;00m _pywrap_tensorflow  \u001B[38;5;66;03m# pylint: disable=unused-import\u001B[39;00m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m module_util \u001B[38;5;28;01mas\u001B[39;00m _module_util\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlazy_loader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasLazyLoader \u001B[38;5;28;01mas\u001B[39;00m _KerasLazyLoader\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:85\u001B[0m\n\u001B[0;32m     83\u001B[0m     sys\u001B[38;5;241m.\u001B[39msetdlopenflags(_default_dlopen_flags)\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[1;32m---> 85\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m     86\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtraceback\u001B[38;5;241m.\u001B[39mformat_exc()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     87\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mFailed to load the native TensorFlow runtime.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     88\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSee https://www.tensorflow.org/install/errors \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     89\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfor some common causes and solutions.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     90\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIf you need help, create an issue \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     91\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     92\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mand include the entire stack trace above this error message.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     94\u001B[0m \u001B[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: Traceback (most recent call last):\n  File \"C:\\Users\\jojo1\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 70, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "execution_count": 3
  }
 ]
}
